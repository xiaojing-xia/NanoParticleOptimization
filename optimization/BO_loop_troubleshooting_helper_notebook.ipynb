{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d4396b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<stdin>:1:10: fatal error: 'omp.h' file not found\n",
      "#include <omp.h>\n",
      "         ^~~~~~~\n",
      "1 error generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : omp.h header is not in the path, disabling OpenMP.\n",
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "from fireworks import LaunchPad\n",
    "from jobflow import JobStore\n",
    "from jobflow.managers.fireworks import flow_to_workflow\n",
    "from maggma.stores.mongolike import MongoStore\n",
    "from NanoParticleTools.flows.flows import get_npmc_flow\n",
    "from NanoParticleTools.inputs.nanoparticle import SphericalConstraint\n",
    "import uuid\n",
    "\n",
    "from botorch.models import SingleTaskGP, ModelListGP\n",
    "from botorch import fit_gpytorch_model\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "from common import seed_generator, configs\n",
    "\n",
    "from common.utils import get_int, get_qe\n",
    "from common import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7486a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import UpperConfidenceBound\n",
    "bounds = torch.tensor([[0., 0., 0., 0., 5./34.], [1., 1., 1., 1., 1.]])\n",
    "candidates = recommend(train_x, train_y, best_y, bounds,1)\n",
    "decode_candidates(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b538c",
   "metadata": {},
   "source": [
    "# submit jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import configs\n",
    "def submit_jobs(candidates):\n",
    "    '''\n",
    "    submit a recipe for simulation\n",
    "    '''\n",
    "    store = JobStore(DOCS_STORE, additional_stores={'trajectories': DATA_STORE})\n",
    "    submitted_id = []\n",
    "    candidates = candidates.tolist()\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        # iterate candidates\n",
    "        dopant_specifications = []\n",
    "        for spec in configs.cfg['dopant_specifications']:\n",
    "            spec = list(spec)\n",
    "            if 'Surface6' in spec:\n",
    "                dopant_specifications.append(tuple(spec))\n",
    "                break\n",
    "            elif spec[1] == -1:\n",
    "                spec[1] = candidate.pop(0)\n",
    "                dopant_specifications.append(tuple(spec))\n",
    "            else:\n",
    "                dopant_specifications.append(tuple(spec))\n",
    "        \n",
    "        constraints = []\n",
    "        for radii in configs.cfg['radius']:\n",
    "            if radii == -1:\n",
    "                constraints.append(SphericalConstraint(candidate.pop(0)))\n",
    "            else:\n",
    "                constraints.append(SphericalConstraint(radii))\n",
    "                \n",
    "        npmc_args = {'npmc_command': configs.cfg['npmc_command'], #NPMC\n",
    "                     'num_sims': configs.cfg['num_sims'], #4\n",
    "                     # 'base_seed': seed_generator.genereate(), #1000\n",
    "                     'base_seed': 1000, \n",
    "                     'thread_count': configs.cfg['ncpu'],\n",
    "                     #'simulation_length': 100000 #\n",
    "                     'simulation_time': configs.cfg['simulation_time'] #0.01s\n",
    "                     }\n",
    "        spectral_kinetics_args = {'excitation_wavelength': configs.cfg['excitation_wavelength'],\n",
    "                                  'excitation_power': configs.cfg['excitation_power']}\n",
    "\n",
    "        initial_state_db_args = {'interaction_radius_bound': configs.cfg['interaction_radius_bound']} #3\n",
    "\n",
    "        # is this being used?\n",
    "        np_uuid = str(uuid.uuid4())\n",
    "\n",
    "        for doping_seed in range(configs.cfg['num_dopant_mc']): #4\n",
    "            flow = get_npmc_flow(constraints=constraints,\n",
    "                                 dopant_specifications=dopant_specifications,\n",
    "                                 # doping_seed=seed_generator.generate(),\n",
    "                                 doping_seed = doping_seed, \n",
    "                                 spectral_kinetics_args=spectral_kinetics_args,\n",
    "                                 initial_state_db_args=initial_state_db_args,\n",
    "                                 npmc_args=npmc_args,\n",
    "                                 output_dir=configs.cfg['output_dir']\n",
    "                                 )\n",
    "\n",
    "            wf = flow_to_workflow(flow, store=store)\n",
    "            mapping = LP.add_wf(wf)\n",
    "            submitted_id.append(list(mapping.values())[0])\n",
    "            \n",
    "        print(f\"Initialized {configs.cfg['num_dopant_mc']} jobs. Submitted {len(submitted_id)}.\")\n",
    "\n",
    "    return submitted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credential\n",
    "LP_FILE = '/Users/xiaojing/my_launchpad.yaml'\n",
    "LP = LaunchPad.from_file(LP_FILE)\n",
    "\n",
    "DOCS_STORE = MongoStore.from_launchpad_file(LP_FILE, 'test_fws_npmc')\n",
    "DATA_STORE = MongoStore.from_launchpad_file(LP_FILE, 'test_docs_npmc')\n",
    "LAUNCH_STORE = MongoStore.from_launchpad_file(LP_FILE, 'launches')\n",
    "\n",
    "DATETIME_FORMAT = \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "#fw_ids = submit_jobs(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d74e16",
   "metadata": {},
   "source": [
    "# recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9f8daf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.optim import optimize_acqf_discrete_local_search\n",
    "def recommend(train_x, train_y, discrete_choices, n_trails, inequality_constraints ):\n",
    "    single_model = SingleTaskGP(train_x, train_y)\n",
    "    mll = ExactMarginalLogLikelihood(single_model.likelihood, single_model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    \n",
    "    # Expected Improvement acquisition function\n",
    "    # EI = qExpectedImprovement(model = single_model, best_f = best_y)\n",
    "    # Upper Confidence Bound acquisition function\n",
    "    UCB = UpperConfidenceBound(single_model, beta=100)\n",
    "    \n",
    "    # hyperparameters are super sensitive here\n",
    "    candidates, _ = optimize_acqf_discrete_local_search(acq_function = UCB,\n",
    "                                                        discrete_choices = discrete_choices,\n",
    "                                                        q = n_trails, \n",
    "                                                        inequality_constraints = inequality_constraints ,\n",
    "                                                        num_restarts = 20, \n",
    "                                                        raw_samples = 512, \n",
    "                                # options = {'batch_limit': 5, \"maxiter\": 200}\n",
    "                                 )\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def get_data_botorch(data_file, from_cloud = True):\n",
    "    if from_cloud:\n",
    "        #df=pd.read_csv('../saved_data/UV_log_shuffled_10initial_test1.csv', sep=',')\n",
    "        df = gcloud_utils.get_df_gspread(GSPREAD_CRED, GSPREAD_NAME)\n",
    "        #df = df.drop(labels=range(1, 570), axis=0)\n",
    "        my_data = df.to_numpy()\n",
    "        print(f\"reading data log from google sheet: {GSPREAD_NAME}!\")\n",
    "    else:\n",
    "        my_data = np.loadtxt(data_file, delimiter=',', skiprows=1)\n",
    "        print(f\"reading data log from local: {data_file}!\")\n",
    "\n",
    "    # features\n",
    "    train_x = torch.from_numpy(my_data[:, :7])\n",
    "    # labels\n",
    "    train_y = torch.from_numpy(my_data[:, 8]).unsqueeze(-1)\n",
    "    # best observation\n",
    "    best_y = train_y.max().item()\n",
    "    \n",
    "    return train_x, train_y, best_y\n",
    "\n",
    "    \n",
    "    return train_x, train_y, best_y\n",
    "def encode_inputs(x_arr, x_max = 34):\n",
    "    '''encode simulation input to botorch'''\n",
    "    for i, arr in enumerate(x_arr):\n",
    "        x_arr[i, 0] = arr[0] + arr[1]\n",
    "        if arr[0] + arr[1] == 0:\n",
    "            x_arr[i, 1] = 0.5\n",
    "        else:\n",
    "            x_arr[i, 1] = arr[0] / (arr[0] + arr[1])\n",
    "        x_arr[i, 2] = arr[2] + arr[3]\n",
    "        if arr[2] + arr[3] == 0:\n",
    "            x_arr[i, 3] = 0.5\n",
    "        else:\n",
    "            x_arr[i, 3] = arr[2] / (arr[2] + arr[3])\n",
    "        x_arr[i, 4] = arr[4] / x_max\n",
    "\n",
    "\n",
    "def decode_candidates(x_arr, x_max = 34):\n",
    "    '''decode botorch recommendation candidates for simulation'''\n",
    "    for i, arr in enumerate(x_arr):\n",
    "        x_arr[i, 0], x_arr[i, 1] = arr[0] * arr[1], arr[0] * (1 - arr[1])\n",
    "        x_arr[i, 2], x_arr[i, 3] = arr[2] * arr[3], arr[2] * (1 - arr[3])\n",
    "        x_arr[i, 4] = arr[4] * x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a829785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_radius = np.arange(5,34,2)\n",
    "conc_interval = 0.001\n",
    "range_sum1 = np.linspace(0,1,int(1/conc_interval +1))\n",
    "range_sum2 = np.linspace(0,1,int(1/conc_interval +1))\n",
    "\n",
    "yb1 = torch.tensor(range_sum1)\n",
    "er1 = torch.tensor(range_sum1)\n",
    "tm1 = torch.tensor(range_sum1)\n",
    "yb2 = torch.tensor(range_sum2)\n",
    "er2 = torch.tensor(range_sum2)\n",
    "tm2 = torch.tensor(range_sum1)\n",
    "rdi = torch.tensor(range_radius)\n",
    "discrete_choices = [yb1,er1,tm1,yb2,er2,tm2,rdi]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "87af2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = [[torch.Tensor([0,1,2]).long(),torch.Tensor([-1,-1,-1]), -1],[torch.Tensor([3,4,5]).long(),torch.Tensor([-1,-1,-1]), -1]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "20582ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data log from local: ../saved_data/simulation_log_YbErTm.csv!\n"
     ]
    }
   ],
   "source": [
    "init_x, init_y, best_y = get_data_botorch(\"../saved_data/simulation_log_YbErTm.csv\", from_cloud=False)\n",
    "train_x, train_y = init_x[:20], init_y[:20]\n",
    "#encode_inputs(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "22f36340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.3200e-01, 3.1100e-01, 1.8300e-01, 3.2200e-01, 4.2400e-01, 1.3000e-02,\n",
       "         2.3000e+01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bounds = torch.tensor([[0., 0., 0., 0., 5], [1., 1., 1., 1., 34]])\n",
    "candidates = recommend(train_x, train_y, discrete_choices,1, constraints)\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c045e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.0838e-01, 9.3868e-02, 5.9734e-02, 1.4535e-02, 2.6287e+01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = torch.tensor([[0., 0., 0., 0., 5/34], [1., 1., 1., 1., 1]])\n",
    "candidates = recommend(train_x, train_y, best_y, bounds,1)\n",
    "decode_candidates(candidates)\n",
    "candidates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
